connectors: [
  {
    name: "vfsConnector",
    class: "com.kmwllc.lucille.connector.VFSConnector",
    pipeline: "pipeline1",
    vfsPath: "/Users/joseph/Documents/MigrateEnronToLucille/maildir" # Change this Path to directory of enron
  },
]

pipelines: [
  {
    name: "pipeline1",
    stages: [
      {
        name:"TextExtractor"
        class: "com.kmwllc.lucille.tika.stage.TextExtractor"
        file_path_field: "file_path"
        metadata_prefix: ""
        metadata_blacklist: ["message_bcc", "content_type", "path",
                              "message_raw_header_x_folder", "message_raw_header_x_filename", "message_raw_header_x_origin",
                              "message_from_email", "message_raw_header_content_type", "message_raw_header_x_bcc", "dc_title",
                              "dc_creator", "message_raw_header_content_transfer_encoding", "message_raw_header_mime_version",
                              "x_tika_parsed_by_full_set", "x_tika_parsed_by"]
        tika_config_path: "conf/tika-config.xml"
      },
      {
        name: "renameFields",
        class: "com.kmwllc.lucille.stage.RenameFields"
        fieldMapping: {
          "text": "body",
          "_message_raw_header_message_id": "message_id",
          "_dc_subject": "subject",
          "_message_to": "to",
          "_message_from": "from",
          "_dcterms_created": "date",
          "_message_cc": "cc_raw",
          "_message_raw_header_x_to": "filtered_to",
          "_message_raw_header_x_from": "filtered_from",
          "_message_raw_header_x_cc": "filtered_cc"
        }
        update_mode: "overwrite"
      },
      {
        name: "deleteFields"
        class : "com.kmwllc.lucille.stage.DeleteFields"
        fields : ["file_modification_date", "file_creation_date", "file_size_bytes", "file_content", "_message_from_name"]
      }
    ]
  }
]

indexer {
  type: "OpenSearch"
  class: "com.kmwllc.lucille.indexer.OpenSearchIndexer"
  # the number of milliseconds (since the previous add or flush) beyond which the batch will be considered as expired
  # and ready to flush regardless of its size; defaults to 100
  batchTimeout: 1000
  # maximum size of a batch before it is flushed
  batchSize: 2000
  # field containing an id that should be sent to the destination index/collection for any given doc,
  # in place of the value of the Document.ID_FIELD field
  # idOverrideField: "message_id"
  sendEnabled: false
}


opensearch {
  url: "https://admin:Opensearch5!@localhost:9200"
  index: "enron"
  acceptInvalidCert: true # only enable for testing ssl/https against localhost
}

worker {
  pipeline: "pipeline1"
  threads: 2
  exitOnTimeout: "true"
  # maximum time to spend processing a message, after which the worker will assume a problem and shut down, assuming that
  # worker.exitOnTimeout=true
  maxProcessingSecs: 600 # 10 minutes
  # tell the worker process to generate a heartbeat.log that can be used to check liveness
  enableHeartbeat: true
  # time in ms, between successive updates to heartbeat.log
  period: 6000
}

runner {
  metricsLoggingLevel: "INFO"
}

publisher {
  # this setting controls
  #     1) maximum size of the queue of published documents waiting to be processed
  #     2) maximum size of the queue of completed documents waiting to be indexed
  # e.g. if it is set to 10 then each each queue can contain up to 10 documents for a total of 20
  #
  # attempts to publish beyond this capacity will cause the publisher to block
  # this setting applies only when running Lucille in local / single-JVM mode using a LocalMessageManager
  # this setting affects Lucille's memory footprint as it determines how many in-flight documents can be held in memory at once
  # this setting defaults to 100
  queueCapacity: 100
}



log {
  seconds: 30 # how often components (Publisher, Worker, Indexer) should log a status update
}