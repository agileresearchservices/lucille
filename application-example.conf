# This is a configuration file managed by https://github.com/lightbend/config
# It is in HOCON format, a superset of JSON

#######################
## Connector(s) Config:
connectors: [
    {class: "com.kmwllc.lucille.connector.CSVConnector",
     path: "/Volumes/Work/lucille/src/test/resources/test.csv", name: "connector1", pipeline: "pipeline1"},
    {class: "com.kmwllc.lucille.connector.CSVConnector",
     path: "/Volumes/Work/lucille/src/test/resources/test4.csv", name: "connector2", pipeline: "pipeline2"}
]

#################
## Runner Config:
runner {
  # outputs detailed metrics to the main lucille log at the end of each run
  metricsLoggingLevel: "INFO"
  # sets the connector timeout (in ms), defaults to 86400000ms
  connectorTimeout: 100000
}

####################
## Publisher Config:
publisher {
  # this setting controls
  #     1) maximum size of the queue of published documents waiting to be processed
  #     2) maximum size of the queue of completed documents waiting to be indexed
  # e.g. if it is set to 10 then each each queue can contain up to 10 documents for a total of 20
  #
  # attempts to publish beyond this capacity will cause the publisher to block
  # this setting applies only when running Lucille in local / single-JVM mode using a LocalMessageManager
  # this setting defaults to 100
  queueCapacity: 100
}

######################
## Pipeline(s) Config:
pipelines: [{name: "pipeline1", stages: [{class: "com.kmwllc.lucille.stage.CreateChildrenStage"}]},
            {name: "pipeline2", stages: [{class: "com.kmwllc.lucille.stage.CreateChildrenStage"}]}
]

# alternative syntax for declaring pipelines:
pipelines: [{name: "pipeline1", stages: [{class: "com.kmwllc.lucille.stage.CreateChildrenStage"}]}]
pipelines: ${pipelines} [{name: "pipeline2", stages: [{class: "com.kmwllc.lucille.stage.CreateChildrenStage"}]}]

##################
## Indexer Config:
indexer {
    type: "Solr" # if omitted, defaults to Solr
    batchTimeout: 6000
    batchSize: 100
    idOverrideField: "identification"
    indexOverrideField: "new_index_field"
    ignoreFields: ["ignore_this_field1", "ignore_this_field2"]
    # at the moment, following settings are specific to Solr Indexer
    deletionMarkerField: "is_deleted"
    deletionMarkerFieldValue: "true"
    deleteByFieldField: "field_to_delete"
    deleteByFieldValue: "false"
}

# elastic search
elastic {
  url: "http://localhost:9200"
  index: "index1"
  type: "lucille-type"
  sendEnabled: false
}

# solr basic indexer config
# - uses HTTP2SolrClient, url includes the collection name (i.e. "collection1")
solr {
  url: "http://localhost:8983/solr/collection1"
}

# solr cloud mode with url
# - uses CloudHTTP2SolrClient, url does not provide collection name, instead included as defaultCollection (i.e. "collection2")
solr {
  url: ["http://localhost:8983/solr"]
  useCloudClient: true
  defaultCollection: "collection2"
}

# solr cloud mode with zkHosts
solr {
  useCloudClient: true
  defaultCollection: "collection3"
  zkHosts: ["zookeeper1:2181", "zookeeper2:2181", "zookeeper3:2181"]
  # optional
  zkChroot: "/solr"
}

# zookeeper settings for solr indexer
zookeeper {
  connectString: "localhost:2181"
}

# open search
opensearch {
  url: "https://admin:admin@localhost:9200"
  url: ${?OPENSEARCH_URL} # allow env override
  index: "index2"
  index: ${?OPENSEARCH_INDEX}
  acceptInvalidCert: false # only enable for testing ssl/https against localhost
}

#################
## Worker Config:
worker {
  # maximum number of times across all workers that an attempt should be made to process any given document;
  # when this property is not provided, retries will not be tracked and no limit will be imposed;
  # this property requires that zookeeper is available at the specified zookeeper.connectString
  maxRetries: 2

  # number of worker threads to start for each pipeline when running lucille in local / single-JVM mode
  threads: 2

  # maximum time to spend processing a message, after which the worker will assume a problem and shut down, assuming that
  # worker.exitOnTimeout=true
  maxProcessingSecs: 600 # 10 minutes

  # name of pipeline
  pipeline: "pipeline_name"

  # tells the worker to System.exit(1) assuming that the worker has not polled before the maximum time given
  exitOnTimeout: "true"

  # maximum time for the worker to poll back / process
  maxProcessingSecs: 60000

  # if set to true, will enable heartbeat checks between worker threads to check that they are alive
  enableHeartbeat: true

  # time in ms, between successive heartbeat checks
  period: 6000
}

################
## Kafka Config:
kafka {
  bootstrapServers: "localhost:9092"

  # how long a kafka poll should wait for data before returning an empty record set
  pollIntervalMs: 250

  # maximum time allowed between kafka polls before consumer is evicted from consumer group
  maxPollIntervalSecs: 600 # 10 minutes

  # ID of consumer group that all lucille workers should belong to
  consumerGroupId: "lucille_workers"

  maxRequestSize: 250000000

  securityProtocol: "SSL"

  consumerPropertyFile: ".../consumer-conf/consumer.properties"

  producerPropertyFile: ".../consumer-conf/producer.properties"

  # does not need to be set explicitly, unless you need to use a custom Deserializer
  documentDeserializer: "com.kmwllc.lucille.message.KafkaDocumentDeserializer"

  # does not need to be set explicitly, unless you need to use a custom Serializer
  documentSerializer: "com.kmwllc.lucille.message.KafkaDocumentSerializer"

  # if set to false, will not send document failures / successes as Kafka messages
  events: true

  # can set custom Kafka topic name which contains documents to be processed
  sourceTopic: "pipeline1_source"

  adminPropertyFile: ".../admin-conf/admin.properties"
}

#########
## Misc:
# for the VFSConnector
aws {
  accessKeyId: "${?AWS_ACCESS_KEY_ID}",
  secretAccessKey: "${?AWS_SECRET_ACCESS_KEY}",
  defaultRegion: "${?AWS_DEFAULT_REGION}"
}


# file-to-file-example.conf illustrates how to reference other config files within a config file

log {
  seconds: 30 # how often components (Publisher, Worker, Indexer) should log a status update
}