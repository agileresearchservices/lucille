package com.kmwllc.lucille.callback;

import com.kmwllc.lucille.core.ConfigAccessor;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.UUID;

/**
 * Invokes one or more Connectors in sequence, only starting the next Connector once all the work
 * generated by the previous Connector is fully complete.
 *
 */
public class Runner {

  private static final Logger log = LoggerFactory.getLogger(Runner.class);

  private final String runId;
  private final RunnerDocumentManager runnerDocumentManager;

  public static void main(String[] args) throws Exception {
    new Runner().runConnectors(true);
  }

  public Runner() {
    // generate a unique ID for this run
    this.runId = UUID.randomUUID().toString();
    log.info("runId=" + runId);
    this.runnerDocumentManager = new RunnerDocumentManager(runId);
  }

  public void runConnectors(boolean startWorkerAndIndexer) throws Exception {

    Worker worker = null;
    Indexer indexer = null;

    if (startWorkerAndIndexer) {
      indexer = new Indexer();
      worker = new Worker();
      Thread workerThread = new Thread(worker);
      Thread indexerThread = new Thread(indexer);
      indexerThread.start();
      workerThread.start();
    }

    List<Connector> connectors = Connector.fromConfig(ConfigAccessor.loadConfig());

    // run all the connectors in sequence, only starting the next connector once all the work
    // generated by the previous connector has been completed
    for (Connector connector : connectors) {
      runConnector(connector);
    }

    if (indexer!=null) {
      indexer.terminate();
    }

    if (worker!=null) {
      worker.terminate();
    }

    runnerDocumentManager.close();
  }

  public void runConnector(Connector connector) throws Exception {

    log.info("Running connector: " + connector.toString());

    // TODO: consider changing these to ConcurrentHashSets, but also consider how we should handle duplicate doc IDs
    List<String> expectedIds = Collections.synchronizedList(new ArrayList<String>());
    List<String> earlyIds = Collections.synchronizedList(new ArrayList<String>());
    Publisher publisher = new Publisher(runId, expectedIds);

    Thread connectorThread = new Thread(new Runnable() {
      @Override
      public void run() {
        connector.connect(publisher);
      }
    });
    connectorThread.start();

    while (true) {
      Event event = runnerDocumentManager.retrieveConfirmation();

      if (event !=null) {
        log.info("RETRIEVED EVENT: " + event);

        String docId = event.getDocumentId();

        if (event.isCreate()) {
          if (!earlyIds.remove(docId)) {
            expectedIds.add(docId);
          }
        } else {
          if (!expectedIds.remove(docId)) {
            earlyIds.add(docId);
          }
        }
      }

      if (expectedIds.isEmpty() && earlyIds.isEmpty() && runnerDocumentManager.isEventTopicEmpty(runId) &&
        !connectorThread.isAlive()) {
        break;
      }

      log.info("waiting on " + expectedIds.size() + " expected index events; " +
        earlyIds.size() + " early confirmations");
    }

    log.info("Work complete");
  }

}
