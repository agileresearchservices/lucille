package com.kmwllc.lucille.callback;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.UUID;

public class Runner {

  private static final Logger log = LoggerFactory.getLogger(Runner.class);

  private final String runId;
  private final RunnerDocumentManager runnerDocumentManager;

  public static void main(String[] args) throws Exception {
    new Runner().runConnectors();
  }

  public Runner() {
    // generate a unique ID for this run
    this.runId = UUID.randomUUID().toString();
    log.info("runId=" + runId);
    this.runnerDocumentManager = new RunnerDocumentManager(runId);
  }

  public void runConnectors() throws Exception {

    // start an Indexer and a Worker as separate threads
    // in an eventual deployment, these would be long-running processes started separately;
    // for now, they're threads that we start here
    Indexer indexer = new Indexer();
    Worker worker = new Worker();
    Thread workerThread = new Thread(worker);
    Thread indexerThread = new Thread(indexer);
    indexerThread.start();
    workerThread.start();

    // create a list of Connectors to run
    // eventually this will be driven by a config file
    List<Connector> connectors = new ArrayList<>();
    connectors.add(new CSVConnector(runId, "/Volumes/Work/lucille/test.csv"));

    // run all the connectors in sequence, only starting the next connector once all the work
    // generated by the previous connector has been completed
    for (Connector connector : connectors) {
      runConnector(connector);
    }

    indexer.terminate();
    worker.terminate();
    runnerDocumentManager.close();
  }

  public void runConnector(Connector connector) throws Exception {
    ConnectorDocumentManager connectorDocumentManager = new ConnectorDocumentManager();

    // TODO: consider changing these to ConcurrentHashSets, but also consider how we should handle duplicate doc IDs
    List<String> expectedIds = Collections.synchronizedList(new ArrayList<String>());
    List<String> earlyIds = Collections.synchronizedList(new ArrayList<String>());

    Thread connectorThread = new Thread(new Runnable() {
      @Override
      public void run() {
        connector.connect(expectedIds, connectorDocumentManager);
      }
    });
    connectorThread.start();

    while (true) {
      Event event = runnerDocumentManager.retrieveConfirmation();

      if (event !=null) {
        log.info("RETRIEVED CONFIRMATION: " + event);

        String docId = event.getDocumentId();

        if (event.isCreate()) {
          if (!earlyIds.remove(docId)) {
            expectedIds.add(docId);
          }
        } else {
          if (!expectedIds.remove(docId)) {
            earlyIds.add(docId);
          }
        }
      }

      if (expectedIds.isEmpty() && earlyIds.isEmpty() && runnerDocumentManager.isEventTopicEmpty(runId) &&
        !connectorThread.isAlive()) {
        break;
      }

      log.info("waiting on " + expectedIds.size() + " expected confirmations; " +
        earlyIds.size() + " early confirmations");
      //Thread.sleep(500);
    }

    log.info("all receipts closed");
  }

}
